{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdUlucrA2vK5tWAzZn2Rcw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leeCodingStudio/Python_machine_learning/blob/master/16_%EB%94%A5%EB%9F%AC%EB%8B%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 퍼셉트론(Perceptron)"
      ],
      "metadata": {
        "id": "sDOeffXNfN3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1-1. 생물학전 뉴런\n",
        "* 인간의 뇌는 수십억 개의 뉴런을 가지고 있음\n",
        "* 뉴런은 화학적, 전기적 신호를 처리하고 전달하는 연결된 뇌신경 세포\n",
        "\n",
        "![](https://i.imgur.com/j3yx4zF.jpg)"
      ],
      "metadata": {
        "id": "u9cHoHt8gKO6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1-2. 인공 뉴런(Perceptron)\n",
        "* 1943년에 워렌 맥컬록, 월터 피츠 단순화된 뇌세포 개념을 발표\n",
        "* 신경 세포를 이진 출력을 가진 단순한 논리 게이트라고 설명\n",
        "* 생물학적 뉴런의 모델에 기초한 수학적 기능으로, 각 뉴런이 입력을 받아 개별적으로 가중치를 곱하여 나온 합계를 비선형 함수를 전달하여 출력을 생성"
      ],
      "metadata": {
        "id": "_05lGaZjglGe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1-3. 논리 회귀(단출 퍼셉트론)로 OR, AND 문제 풀기\n",
        "\n",
        "![](https://i.imgur.com/AaAGC7g.jpg)"
      ],
      "metadata": {
        "id": "NlkRM0JRhZAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "wT2iKF8-hkeT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = torch.FloatTensor([[0], [1], [1], [1]])"
      ],
      "metadata": {
        "id": "rMxayMr0iC3d"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(2, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTwCQAS_iZd5",
        "outputId": "d23150ce-5f5d-4efe-8f2b-49687b7dc8d9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=2, out_features=1, bias=True)\n",
            "  (1): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=1)\n",
        "\n",
        "epochs = 1000\n",
        "\n",
        "for epoch in range(epochs + 1):\n",
        "    y_pred = model(X)\n",
        "    loss = nn.BCELoss()(y_pred, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        y_bool = (y_pred >= 0.5).float()\n",
        "        accuracy = (y == y_bool).float().sum() / len(y) * 100\n",
        "\n",
        "        print(f'Epoch {epoch:4d}/{epochs} Loss: {loss:.6f} Accuracy: {accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQx3Qlo9id5t",
        "outputId": "7f31baf6-a0c8-4bf1-fafd-f6034b7b9f6b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Loss: 0.626946 Accuracy: 50.00\n",
            "Epoch  100/1000 Loss: 0.091468 Accuracy: 100.00\n",
            "Epoch  200/1000 Loss: 0.047505 Accuracy: 100.00\n",
            "Epoch  300/1000 Loss: 0.031712 Accuracy: 100.00\n",
            "Epoch  400/1000 Loss: 0.023702 Accuracy: 100.00\n",
            "Epoch  500/1000 Loss: 0.018887 Accuracy: 100.00\n",
            "Epoch  600/1000 Loss: 0.015682 Accuracy: 100.00\n",
            "Epoch  700/1000 Loss: 0.013399 Accuracy: 100.00\n",
            "Epoch  800/1000 Loss: 0.011692 Accuracy: 100.00\n",
            "Epoch  900/1000 Loss: 0.010368 Accuracy: 100.00\n",
            "Epoch 1000/1000 Loss: 0.009312 Accuracy: 100.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1-4. 논리 회귀(단층 퍼셉트론)로 AND 문제 풀기\n",
        "\n",
        "![](https://i.imgur.com/yt7O7TV.jpg)"
      ],
      "metadata": {
        "id": "U8rXFZfJjSad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = torch.FloatTensor([[0], [0], [0], [1]])\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(2, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=1)\n",
        "\n",
        "epochs = 1000\n",
        "\n",
        "for epoch in range(epochs + 1):\n",
        "    y_pred = model(X)\n",
        "    loss = nn.BCELoss()(y_pred, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        y_bool = (y_pred >= 0.5).float()\n",
        "        accuracy = (y == y_bool).float().sum() / len(y) * 100\n",
        "\n",
        "        print(f'Epoch {epoch:4d}/{epochs} Loss: {loss:.6f} Accuracy: {accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPdy8xYGnFzg",
        "outputId": "f81e3ab0-35b0-415c-a9db-f38cad6d3fdb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Loss: 0.631607 Accuracy: 75.00\n",
            "Epoch  100/1000 Loss: 0.141134 Accuracy: 100.00\n",
            "Epoch  200/1000 Loss: 0.080766 Accuracy: 100.00\n",
            "Epoch  300/1000 Loss: 0.056088 Accuracy: 100.00\n",
            "Epoch  400/1000 Loss: 0.042781 Accuracy: 100.00\n",
            "Epoch  500/1000 Loss: 0.034502 Accuracy: 100.00\n",
            "Epoch  600/1000 Loss: 0.028870 Accuracy: 100.00\n",
            "Epoch  700/1000 Loss: 0.024800 Accuracy: 100.00\n",
            "Epoch  800/1000 Loss: 0.021723 Accuracy: 100.00\n",
            "Epoch  900/1000 Loss: 0.019319 Accuracy: 100.00\n",
            "Epoch 1000/1000 Loss: 0.017389 Accuracy: 100.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1-5. 논리 회귀(단층 퍼셉트론)로 XOR 문제 풀기\n",
        "\n",
        "![](https://i.imgur.com/55pt51n.png)"
      ],
      "metadata": {
        "id": "LkO7iUXZnPT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = torch.FloatTensor([[0], [1], [1], [0]])\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(2, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=1)\n",
        "\n",
        "epochs = 1000\n",
        "\n",
        "for epoch in range(epochs + 1):\n",
        "    y_pred = model(X)\n",
        "    loss = nn.BCELoss()(y_pred, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        y_bool = (y_pred >= 0.5).float()\n",
        "        accuracy = (y == y_bool).float().sum() / len(y) * 100\n",
        "\n",
        "        print(f'Epoch {epoch:4d}/{epochs} Loss: {loss:.6f} Accuracy: {accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uvn_S2kBnxKA",
        "outputId": "d28d8c38-a15a-4d6d-fd25-f5b141a29542"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Loss: 0.797920 Accuracy: 50.00\n",
            "Epoch  100/1000 Loss: 0.693147 Accuracy: 50.00\n",
            "Epoch  200/1000 Loss: 0.693147 Accuracy: 25.00\n",
            "Epoch  300/1000 Loss: 0.693147 Accuracy: 75.00\n",
            "Epoch  400/1000 Loss: 0.693147 Accuracy: 50.00\n",
            "Epoch  500/1000 Loss: 0.693147 Accuracy: 50.00\n",
            "Epoch  600/1000 Loss: 0.693147 Accuracy: 50.00\n",
            "Epoch  700/1000 Loss: 0.693147 Accuracy: 50.00\n",
            "Epoch  800/1000 Loss: 0.693147 Accuracy: 50.00\n",
            "Epoch  900/1000 Loss: 0.693147 Accuracy: 50.00\n",
            "Epoch 1000/1000 Loss: 0.693147 Accuracy: 50.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 역전파(Backpropagation)\n",
        "* 1974, by Paul Werbos\n",
        "* 1986, by Hinton\n",
        "\n",
        "<img src=\"https://i.imgur.com/QtiHBAE.png\" width=\"800px\">"
      ],
      "metadata": {
        "id": "YoF-xaMun5ho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(2, 64),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(64, 32),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(32, 16),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(16, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6MKnJGPpr56",
        "outputId": "e47401ca-0f70-4d99-9350-94a11d58f887"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=2, out_features=64, bias=True)\n",
            "  (1): Sigmoid()\n",
            "  (2): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (3): Sigmoid()\n",
            "  (4): Linear(in_features=32, out_features=16, bias=True)\n",
            "  (5): Sigmoid()\n",
            "  (6): Linear(in_features=16, out_features=1, bias=True)\n",
            "  (7): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = torch.FloatTensor([[0], [1], [1], [0]])\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=1)\n",
        "\n",
        "epochs = 5000\n",
        "\n",
        "for epoch in range(epochs + 1):\n",
        "    y_pred = model(X)\n",
        "    loss = nn.BCELoss()(y_pred, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        y_bool = (y_pred >= 0.5).float()\n",
        "        accuracy = (y == y_bool).float().sum() / len(y) * 100\n",
        "\n",
        "        print(f'Epoch {epoch:4d}/{epochs} Loss: {loss:.6f} Accuracy: {accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr2PUil0qooH",
        "outputId": "e509b365-c7ef-47ff-ccd3-41a86e474830"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/5000 Loss: 0.701658 Accuracy: 50.00\n",
            "Epoch  100/5000 Loss: 0.693139 Accuracy: 50.00\n",
            "Epoch  200/5000 Loss: 0.693136 Accuracy: 50.00\n",
            "Epoch  300/5000 Loss: 0.693133 Accuracy: 50.00\n",
            "Epoch  400/5000 Loss: 0.693129 Accuracy: 50.00\n",
            "Epoch  500/5000 Loss: 0.693125 Accuracy: 50.00\n",
            "Epoch  600/5000 Loss: 0.693121 Accuracy: 50.00\n",
            "Epoch  700/5000 Loss: 0.693117 Accuracy: 50.00\n",
            "Epoch  800/5000 Loss: 0.693112 Accuracy: 50.00\n",
            "Epoch  900/5000 Loss: 0.693107 Accuracy: 50.00\n",
            "Epoch 1000/5000 Loss: 0.693101 Accuracy: 50.00\n",
            "Epoch 1100/5000 Loss: 0.693095 Accuracy: 50.00\n",
            "Epoch 1200/5000 Loss: 0.693088 Accuracy: 50.00\n",
            "Epoch 1300/5000 Loss: 0.693081 Accuracy: 50.00\n",
            "Epoch 1400/5000 Loss: 0.693072 Accuracy: 50.00\n",
            "Epoch 1500/5000 Loss: 0.693062 Accuracy: 50.00\n",
            "Epoch 1600/5000 Loss: 0.693051 Accuracy: 50.00\n",
            "Epoch 1700/5000 Loss: 0.693038 Accuracy: 50.00\n",
            "Epoch 1800/5000 Loss: 0.693023 Accuracy: 50.00\n",
            "Epoch 1900/5000 Loss: 0.693005 Accuracy: 50.00\n",
            "Epoch 2000/5000 Loss: 0.692984 Accuracy: 50.00\n",
            "Epoch 2100/5000 Loss: 0.692959 Accuracy: 50.00\n",
            "Epoch 2200/5000 Loss: 0.692928 Accuracy: 50.00\n",
            "Epoch 2300/5000 Loss: 0.692889 Accuracy: 50.00\n",
            "Epoch 2400/5000 Loss: 0.692840 Accuracy: 50.00\n",
            "Epoch 2500/5000 Loss: 0.692778 Accuracy: 50.00\n",
            "Epoch 2600/5000 Loss: 0.692694 Accuracy: 50.00\n",
            "Epoch 2700/5000 Loss: 0.692581 Accuracy: 50.00\n",
            "Epoch 2800/5000 Loss: 0.692419 Accuracy: 50.00\n",
            "Epoch 2900/5000 Loss: 0.692177 Accuracy: 50.00\n",
            "Epoch 3000/5000 Loss: 0.691788 Accuracy: 50.00\n",
            "Epoch 3100/5000 Loss: 0.691096 Accuracy: 50.00\n",
            "Epoch 3200/5000 Loss: 0.689670 Accuracy: 50.00\n",
            "Epoch 3300/5000 Loss: 0.685924 Accuracy: 50.00\n",
            "Epoch 3400/5000 Loss: 0.791805 Accuracy: 50.00\n",
            "Epoch 3500/5000 Loss: 0.668625 Accuracy: 50.00\n",
            "Epoch 3600/5000 Loss: 0.547393 Accuracy: 50.00\n",
            "Epoch 3700/5000 Loss: 0.329915 Accuracy: 100.00\n",
            "Epoch 3800/5000 Loss: 0.012595 Accuracy: 100.00\n",
            "Epoch 3900/5000 Loss: 0.005424 Accuracy: 100.00\n",
            "Epoch 4000/5000 Loss: 0.003303 Accuracy: 100.00\n",
            "Epoch 4100/5000 Loss: 0.002328 Accuracy: 100.00\n",
            "Epoch 4200/5000 Loss: 0.001777 Accuracy: 100.00\n",
            "Epoch 4300/5000 Loss: 0.001427 Accuracy: 100.00\n",
            "Epoch 4400/5000 Loss: 0.001187 Accuracy: 100.00\n",
            "Epoch 4500/5000 Loss: 0.001012 Accuracy: 100.00\n",
            "Epoch 4600/5000 Loss: 0.000880 Accuracy: 100.00\n",
            "Epoch 4700/5000 Loss: 0.000777 Accuracy: 100.00\n",
            "Epoch 4800/5000 Loss: 0.000694 Accuracy: 100.00\n",
            "Epoch 4900/5000 Loss: 0.000627 Accuracy: 100.00\n",
            "Epoch 5000/5000 Loss: 0.000571 Accuracy: 100.00\n"
          ]
        }
      ]
    }
  ]
}